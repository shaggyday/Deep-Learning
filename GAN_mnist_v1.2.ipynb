{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generator_model():\n",
    "    dropout = 0.4\n",
    "    dim = 7\n",
    "    depth = 256\n",
    "    # In: 100\n",
    "    # Out: 7 x 7 x 256\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dim*dim*depth, input_dim=100))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Reshape((dim, dim, depth)))\n",
    "    model.add(Dropout(dropout))\n",
    "    # In: 7 x 7 x 256\n",
    "    # Out: 14 x 14 x 128\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(LeakyReLU())\n",
    "    # In: 14 x 14 x 128\n",
    "    # Out: 28 x 28 x 64\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(LeakyReLU())\n",
    "    # In: 28 x 28 x 64\n",
    "    # Out: 28 x 28 x 1\n",
    "    model.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def discriminator_model():\n",
    "    depth = 64\n",
    "    dropout = 0.4\n",
    "    model = Sequential()\n",
    "    # In: 28 x 28 x 1, depth = 1\n",
    "    # Out: 14 x 14 x 1, depth = 64\n",
    "    model.add(Conv2D(depth, 5, strides = 2, padding ='same', input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(depth*2, 5, strides = 2, padding ='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(depth*4, 5, strides = 2, padding ='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(depth*8, 5, strides = 1, padding ='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    # Out: 1-dim probability\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def adversial_model(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-7a8930740c1d>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 8193      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,394,241\n",
      "Trainable params: 2,368,705\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0: [D loss: 0.692482, acc: 0.515625]  [A loss: 0.837278, acc: 0.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [D loss: 0.653254, acc: 0.517578]  [A loss: 1.133525, acc: 0.000000]\n",
      "2: [D loss: 0.613652, acc: 0.505859]  [A loss: 1.518298, acc: 0.000000]\n",
      "3: [D loss: 0.544940, acc: 0.542969]  [A loss: 1.658825, acc: 0.000000]\n",
      "4: [D loss: 0.406807, acc: 0.884766]  [A loss: 1.617806, acc: 0.000000]\n",
      "5: [D loss: 0.242300, acc: 0.988281]  [A loss: 1.815567, acc: 0.003906]\n",
      "6: [D loss: 0.118002, acc: 0.988281]  [A loss: 0.093768, acc: 1.000000]\n",
      "7: [D loss: 0.420429, acc: 0.746094]  [A loss: 4.659871, acc: 0.000000]\n",
      "8: [D loss: 0.209876, acc: 0.925781]  [A loss: 6.595488, acc: 0.000000]\n",
      "9: [D loss: 0.374879, acc: 0.853516]  [A loss: 2.821413, acc: 0.050781]\n",
      "10: [D loss: 0.185084, acc: 0.927734]  [A loss: 0.173619, acc: 0.937500]\n",
      "11: [D loss: 0.067754, acc: 0.970703]  [A loss: 0.006156, acc: 1.000000]\n",
      "12: [D loss: 0.183920, acc: 0.916016]  [A loss: 0.330329, acc: 0.855469]\n",
      "13: [D loss: 0.089394, acc: 0.966797]  [A loss: 0.843222, acc: 0.589844]\n",
      "14: [D loss: 0.101791, acc: 0.968750]  [A loss: 0.575104, acc: 0.742188]\n",
      "15: [D loss: 0.173123, acc: 0.943359]  [A loss: 0.510428, acc: 0.792969]\n",
      "16: [D loss: 0.209234, acc: 0.914062]  [A loss: 5.547337, acc: 0.000000]\n",
      "17: [D loss: 0.335389, acc: 0.863281]  [A loss: 2.278890, acc: 0.128906]\n",
      "18: [D loss: 0.184770, acc: 0.927734]  [A loss: 0.561200, acc: 0.750000]\n",
      "19: [D loss: 0.369454, acc: 0.806641]  [A loss: 13.073915, acc: 0.000000]\n",
      "20: [D loss: 1.365973, acc: 0.582031]  [A loss: 5.944540, acc: 0.000000]\n",
      "21: [D loss: 0.227608, acc: 0.923828]  [A loss: 0.216818, acc: 0.937500]\n",
      "22: [D loss: 0.142200, acc: 0.945312]  [A loss: 1.033852, acc: 0.476562]\n",
      "23: [D loss: 0.056982, acc: 0.984375]  [A loss: 1.538415, acc: 0.335938]\n",
      "24: [D loss: 0.043361, acc: 0.992188]  [A loss: 1.016858, acc: 0.519531]\n",
      "25: [D loss: 0.051780, acc: 0.986328]  [A loss: 0.674008, acc: 0.710938]\n",
      "26: [D loss: 0.091612, acc: 0.976562]  [A loss: 2.714386, acc: 0.062500]\n",
      "27: [D loss: 0.100786, acc: 0.974609]  [A loss: 2.340136, acc: 0.144531]\n",
      "28: [D loss: 0.088483, acc: 0.970703]  [A loss: 2.271078, acc: 0.101562]\n",
      "29: [D loss: 0.132487, acc: 0.949219]  [A loss: 4.969423, acc: 0.000000]\n",
      "30: [D loss: 0.150771, acc: 0.951172]  [A loss: 2.876621, acc: 0.039062]\n",
      "31: [D loss: 0.162052, acc: 0.960938]  [A loss: 7.055637, acc: 0.000000]\n",
      "32: [D loss: 0.262977, acc: 0.900391]  [A loss: 2.938840, acc: 0.011719]\n",
      "33: [D loss: 0.325979, acc: 0.820312]  [A loss: 14.234331, acc: 0.000000]\n",
      "34: [D loss: 1.425149, acc: 0.625000]  [A loss: 6.177199, acc: 0.000000]\n",
      "35: [D loss: 0.308587, acc: 0.890625]  [A loss: 5.896030, acc: 0.000000]\n",
      "36: [D loss: 0.355560, acc: 0.832031]  [A loss: 9.160103, acc: 0.000000]\n",
      "37: [D loss: 0.701233, acc: 0.669922]  [A loss: 7.920818, acc: 0.000000]\n",
      "38: [D loss: 1.061458, acc: 0.365234]  [A loss: 4.347385, acc: 0.000000]\n",
      "39: [D loss: 0.631465, acc: 0.505859]  [A loss: 3.561274, acc: 0.000000]\n",
      "40: [D loss: 0.280256, acc: 0.910156]  [A loss: 4.722740, acc: 0.000000]\n",
      "41: [D loss: 0.180798, acc: 0.968750]  [A loss: 4.062569, acc: 0.000000]\n",
      "42: [D loss: 0.143539, acc: 0.982422]  [A loss: 3.216341, acc: 0.000000]\n",
      "43: [D loss: 0.138339, acc: 0.986328]  [A loss: 3.290589, acc: 0.000000]\n",
      "44: [D loss: 0.113304, acc: 0.996094]  [A loss: 3.659113, acc: 0.000000]\n",
      "45: [D loss: 0.133221, acc: 0.988281]  [A loss: 3.655468, acc: 0.000000]\n",
      "46: [D loss: 0.162855, acc: 0.986328]  [A loss: 3.853413, acc: 0.000000]\n",
      "47: [D loss: 0.187562, acc: 0.974609]  [A loss: 3.840058, acc: 0.000000]\n",
      "48: [D loss: 0.189380, acc: 0.964844]  [A loss: 3.540878, acc: 0.000000]\n",
      "49: [D loss: 0.143471, acc: 0.978516]  [A loss: 3.346239, acc: 0.000000]\n",
      "50: [D loss: 0.113239, acc: 0.978516]  [A loss: 3.069974, acc: 0.003906]\n",
      "51: [D loss: 0.077356, acc: 0.992188]  [A loss: 3.015105, acc: 0.007812]\n",
      "52: [D loss: 0.073525, acc: 0.988281]  [A loss: 2.744599, acc: 0.011719]\n",
      "53: [D loss: 0.081317, acc: 0.986328]  [A loss: 3.217104, acc: 0.007812]\n",
      "54: [D loss: 0.072180, acc: 0.988281]  [A loss: 2.843863, acc: 0.011719]\n",
      "55: [D loss: 0.070209, acc: 0.990234]  [A loss: 2.445527, acc: 0.046875]\n",
      "56: [D loss: 0.056095, acc: 0.992188]  [A loss: 2.473980, acc: 0.062500]\n",
      "57: [D loss: 0.052312, acc: 0.990234]  [A loss: 2.219443, acc: 0.085938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-7a8930740c1d>\", line 62, in <module>\n",
      "    train()\n",
      "  File \"<ipython-input-2-7a8930740c1d>\", line 39, in train\n",
      "    a_loss = adversial.train_on_batch(random_latent_vectors, misleading_targets)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1217, in train_on_batch\n",
      "    outputs = self.train_function(ins)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2715, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2675, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1439, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 179, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"C:\\Users\\shaggyday\\Anaconda3\\lib\\tokenize.py\", line 447, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "def train(epochs = 1000, batch_size = 256, save_interval = 50):\n",
    "    latent_dim = 100\n",
    "    img_cols, img_rows = 28, 28\n",
    "    # Initialize data and models\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = input_data.read_data_sets(\"mnist\",one_hot=True).train.images\n",
    "    X_train = X_train.reshape(-1, img_cols, img_rows, 1).astype(np.float32)\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    adversial = adversial_model(generator, discriminator) # discriminator is frozen\n",
    "    d_optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    g_optim = Adam(lr=0.0001, beta_1=0.5)\n",
    "#     generator.compile(loss='binary_crossentropy', optimizer=\"RMSprop\")\n",
    "    adversial.compile(loss='binary_crossentropy', optimizer=g_optim, metrics=['accuracy'])\n",
    "    discriminator.trainable = True # unfreeze discriminator\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim, metrics=['accuracy'])\n",
    "    \n",
    "    # Stuff for saving images\n",
    "    filename = 'mnist.png'\n",
    "    noise_input = None\n",
    "    if save_interval > 0:\n",
    "        noise_input = np.random.uniform(-1, 1, size=[16, latent_dim])\n",
    "    \n",
    "    # The training loop\n",
    "    for epoch in range(epochs):\n",
    "        real_images = X_train[np.random.randint(0, X_train.shape[0], size=batch_size), :, :, :]\n",
    "        noise = np.random.uniform(-1, 1, size=[batch_size, latent_dim])\n",
    "        fake_images = generator.predict(noise)\n",
    "        combined_images = np.concatenate((real_images, fake_images))\n",
    "        labels = np.ones([2*batch_size, 1])\n",
    "        labels[batch_size:, :] = 0\n",
    "#         labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "#         labels += 0.05 * np.random.random(labels.shape)\n",
    "        d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "                                        \n",
    "        misleading_targets = np.ones([batch_size, 1])\n",
    "        random_latent_vectors = np.random.uniform(-1, 1, size=[batch_size, latent_dim])\n",
    "        discriminator.trainable = False # freeze the discriminator\n",
    "        a_loss = adversial.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "        discriminator.trainable = True # unfreeze the discrminator\n",
    "                                        \n",
    "        log_mesg = \"%d: [D loss: %f, acc: %f]\" % (epoch, d_loss[0], d_loss[1])\n",
    "        log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "        print(log_mesg)\n",
    "                       \n",
    "        # Saving sample generated images\n",
    "        if save_interval>0:\n",
    "            step = epoch+1\n",
    "            if step%save_interval==0:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "                images = generator.predict(noise_input)\n",
    "                plt.figure(figsize=(10,10))\n",
    "                for i in range(images.shape[0]):\n",
    "                    plt.subplot(4, 4, i+1)\n",
    "                    image = images[i, :, :, :]\n",
    "                    image = np.reshape(image, [img_cols, img_rows])\n",
    "                    plt.imshow(image, cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(filename)\n",
    "                plt.close('all')\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
